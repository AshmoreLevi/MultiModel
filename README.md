# MultiModel - å¤šæ¨¡æ€æœºå™¨å­¦ä¹ é¡¹ç›®

ä¸€ä¸ªå¼ºå¤§çš„å¤šæ¨¡æ€æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§æ•°æ®æ¨¡æ€çš„å¤„ç†ã€ç‰¹å¾æå–å’Œèåˆã€‚

## ğŸš€ é¡¹ç›®ç‰¹æ€§

- **å¤šæ¨¡æ€æ”¯æŒ**: é›†æˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å¤„ç†èƒ½åŠ›
- **ç‰¹å¾æå–**: ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æå–é«˜è´¨é‡ç‰¹å¾
- **æ¨¡æ€èåˆ**: æ”¯æŒå¤šç§èåˆç­–ç•¥ï¼ˆè¿æ¥ã€æ³¨æ„åŠ›ã€åŠ æƒã€PCAç­‰ï¼‰
- **æ˜“äºä½¿ç”¨**: æä¾›ç®€æ´çš„APIå’Œå‘½ä»¤è¡Œå·¥å…·
- **å¯æ‰©å±•æ€§**: æ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºæ·»åŠ æ–°çš„æ¨¡æ€å’Œç®—æ³•
- **Apple Siliconä¼˜åŒ–**: åŸç”Ÿæ”¯æŒMac Mç³»åˆ—èŠ¯ç‰‡ï¼Œä½¿ç”¨MPSåŠ é€Ÿ

## ğŸ Mac Mç³»åˆ—èŠ¯ç‰‡ç”¨æˆ·

**å¿«é€Ÿå¼€å§‹**: ä½¿ç”¨æˆ‘ä»¬çš„ä¸€é”®å®‰è£…è„šæœ¬

```bash
git clone <your-repo-url>
cd MultiModel
./install_mac_m.sh
```

ğŸ“– [å®Œæ•´çš„Mac Mç³»åˆ—ä½¿ç”¨æŒ‡å—](MAC_M_SERIES_GUIDE.md)

## ğŸ“¦ å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 2.0+
- å¯¹äºMac Mç³»åˆ—èŠ¯ç‰‡ï¼šæ¨èä½¿ç”¨condaè¿›è¡Œç¯å¢ƒç®¡ç†
- å…¶ä»–ä¾èµ–è§ `requirements.txt` æˆ– `environment.yml`

### å®‰è£…æ­¥éª¤

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨condaï¼ˆæ¨èï¼Œç‰¹åˆ«æ˜¯Mac Mç³»åˆ—èŠ¯ç‰‡ï¼‰

1. å…‹éš†é¡¹ç›®
```bash
git clone <your-repo-url>
cd MultiModel
```

2. åˆ›å»ºcondaç¯å¢ƒ
```bash
# ä½¿ç”¨environment.ymlåˆ›å»ºç¯å¢ƒï¼ˆæ¨èï¼‰
conda env create -f environment.yml

# æ¿€æ´»ç¯å¢ƒ
conda activate multimodel
```

3. å®‰è£…é¡¹ç›®
```bash
pip install -e .
```

#### æ–¹æ³•äºŒï¼šä½¿ç”¨pipï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰

1. å…‹éš†é¡¹ç›®
```bash
git clone <your-repo-url>
cd MultiModel
```

2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\Scripts\activate  # Windows
```

3. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

4. å®‰è£…é¡¹ç›®
```bash
pip install -e .
```

#### Mac Mç³»åˆ—èŠ¯ç‰‡ç‰¹åˆ«è¯´æ˜

- å·²é’ˆå¯¹Apple Siliconè¿›è¡Œä¼˜åŒ–
- è‡ªåŠ¨ä½¿ç”¨Metal Performance Shaders (MPS)è¿›è¡ŒGPUåŠ é€Ÿ
- ç§»é™¤äº†CUDAä¾èµ–ï¼Œæ”¹ç”¨Apple SiliconåŸç”Ÿæ”¯æŒ

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### Python API ä½¿ç”¨

```python
from multimodel import TextProcessor, ImageProcessor, AudioProcessor, MultimodalFusion

# æ–‡æœ¬å¤„ç†
text_processor = TextProcessor()
text_features = text_processor.extract_features("è¿™æ˜¯ä¸€æ®µç¤ºä¾‹æ–‡æœ¬")

# å›¾åƒå¤„ç†
image_processor = ImageProcessor()
image = image_processor.load_image("path/to/image.jpg")
image_features = image_processor.extract_features(image)

# éŸ³é¢‘å¤„ç†
audio_processor = AudioProcessor()
audio_data, sr = audio_processor.load_audio("path/to/audio.wav")
audio_features = audio_processor.extract_comprehensive_features(audio_data)

# å¤šæ¨¡æ€èåˆ
fusion = MultimodalFusion(fusion_method="attention")
result = fusion.fuse_modalities(
    text_features=text_features,
    image_features=image_features,
    audio_features=audio_features['mfcc'].mean(axis=1)
)

print(f"èåˆç‰¹å¾ç»´åº¦: {result['output_shape']}")
```

### å‘½ä»¤è¡Œå·¥å…·ä½¿ç”¨

```bash
# å¤„ç†æ–‡æœ¬
multimodel process-text "ä½ çš„æ–‡æœ¬å†…å®¹" --output result.json

# å¤„ç†å›¾åƒ
multimodel process-image path/to/image.jpg --output ./results/

# å¤„ç†éŸ³é¢‘
multimodel process-audio path/to/audio.wav --duration 10 --output ./results/

# å¤šæ¨¡æ€èåˆ
multimodel fuse --text "æ–‡æœ¬å†…å®¹" --image image.jpg --audio audio.wav --method attention --output fusion_result.json

# è¿è¡Œæ¼”ç¤º
multimodel demo
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
MultiModel/
â”œâ”€â”€ multimodel/              # ä¸»è¦ä»£ç åŒ…
â”‚   â”œâ”€â”€ __init__.py         # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ core/               # æ ¸å¿ƒæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ text_processor.py      # æ–‡æœ¬å¤„ç†
â”‚   â”‚   â”œâ”€â”€ image_processor.py     # å›¾åƒå¤„ç†
â”‚   â”‚   â”œâ”€â”€ audio_processor.py     # éŸ³é¢‘å¤„ç†
â”‚   â”‚   â””â”€â”€ multimodal_fusion.py   # å¤šæ¨¡æ€èåˆ
â”‚   â””â”€â”€ cli.py              # å‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ examples/               # ç¤ºä¾‹ä»£ç 
â”‚   â””â”€â”€ demo.py            # æ¼”ç¤ºç¨‹åº
â”œâ”€â”€ tests/                 # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ requirements.txt       # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ setup.py              # å®‰è£…é…ç½®
â””â”€â”€ README.md             # é¡¹ç›®è¯´æ˜
```

## ğŸ”§ æ ¸å¿ƒæ¨¡å—

### æ–‡æœ¬å¤„ç†å™¨ (TextProcessor)

- **åŠŸèƒ½**: æ–‡æœ¬æ¸…ç†ã€ä¸­æ–‡åˆ†è¯ã€ç‰¹å¾æå–ã€ç»Ÿè®¡åˆ†æ
- **æ”¯æŒæ¨¡å‹**: BERTã€RoBERTaç­‰Transformeræ¨¡å‹
- **ç‰¹å¾**: æ”¯æŒä¸­è‹±æ–‡æ··åˆæ–‡æœ¬å¤„ç†

```python
processor = TextProcessor(model_name="bert-base-chinese")
features = processor.extract_features("ä½ çš„æ–‡æœ¬")
stats = processor.get_text_statistics("ä½ çš„æ–‡æœ¬")
```

### å›¾åƒå¤„ç†å™¨ (ImageProcessor)

- **åŠŸèƒ½**: å›¾åƒé¢„å¤„ç†ã€ç‰¹å¾æå–ã€å¯¹è±¡æ£€æµ‹ã€é¢œè‰²åˆ†æ
- **æ”¯æŒæ¨¡å‹**: ResNetã€VGGç­‰CNNæ¨¡å‹
- **ç‰¹å¾**: è‡ªåŠ¨å›¾åƒå¢å¼ºå’Œç‰¹å¾æ ‡å‡†åŒ–

```python
processor = ImageProcessor(model_name="resnet50")
image = processor.load_image("image.jpg")
features = processor.extract_features(image)
objects = processor.detect_objects(image)
```

### éŸ³é¢‘å¤„ç†å™¨ (AudioProcessor)

- **åŠŸèƒ½**: éŸ³é¢‘é¢„å¤„ç†ã€MFCCæå–ã€é¢‘è°±åˆ†æã€èŠ‚å¥æ£€æµ‹
- **æ”¯æŒæ ¼å¼**: WAVã€MP3ã€FLACç­‰å¸¸è§éŸ³é¢‘æ ¼å¼
- **ç‰¹å¾**: æ¢…å°”é¢‘è°±å›¾ã€è‰²åº¦ç‰¹å¾ã€èŠ‚æ‹è·Ÿè¸ª

```python
processor = AudioProcessor(sample_rate=22050)
audio_data, sr = processor.load_audio("audio.wav")
features = processor.extract_comprehensive_features(audio_data)
```

### å¤šæ¨¡æ€èåˆå™¨ (MultimodalFusion)

- **èåˆæ–¹æ³•**:
  - `concatenation`: ç®€å•ç‰¹å¾è¿æ¥
  - `attention`: æ³¨æ„åŠ›æœºåˆ¶èåˆ
  - `weighted`: åŠ æƒèåˆ
  - `pca`: PCAé™ç»´èåˆ

```python
fusion = MultimodalFusion(fusion_method="attention")
result = fusion.fuse_modalities(
    text_features=text_feat,
    image_features=image_feat,
    audio_features=audio_feat
)
```

## ğŸ“Š ç¤ºä¾‹åº”ç”¨

### 1. æƒ…æ„Ÿåˆ†æ
ç»“åˆæ–‡æœ¬å†…å®¹ã€å›¾åƒæƒ…ç»ªå’ŒéŸ³é¢‘è¯­è°ƒè¿›è¡Œç»¼åˆæƒ…æ„Ÿåˆ†æ

### 2. å†…å®¹ç†è§£
å¤šæ¨¡æ€å†…å®¹æ£€ç´¢å’Œç›¸ä¼¼åº¦åŒ¹é…

### 3. åˆ›æ„ç”Ÿæˆ
åŸºäºå¤šæ¨¡æ€è¾“å…¥çš„åˆ›æ„å†…å®¹ç”Ÿæˆ

### 4. è´¨é‡è¯„ä¼°
å¤šç»´åº¦å†…å®¹è´¨é‡è‡ªåŠ¨è¯„ä¼°

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•å¥—ä»¶ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_text_processor.py

# è¿è¡Œæ¼”ç¤ºç¨‹åº
python examples/demo.py
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

- **GPUåŠ é€Ÿ**: è‡ªåŠ¨æ£€æµ‹CUDAå¹¶ä½¿ç”¨GPUåŠ é€Ÿ
- **æ‰¹å¤„ç†**: æ”¯æŒæ‰¹é‡æ•°æ®å¤„ç†
- **å†…å­˜ä¼˜åŒ–**: å¤§æ–‡ä»¶æµå¼å¤„ç†
- **ç¼“å­˜æœºåˆ¶**: æ¨¡å‹å’Œç‰¹å¾ç¼“å­˜

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®ä½¿ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

## ğŸ“ è”ç³»æˆ‘ä»¬

- é¡¹ç›®é“¾æ¥: [https://github.com/yourusername/multimodel](https://github.com/yourusername/multimodel)
- é—®é¢˜åé¦ˆ: [Issues](https://github.com/yourusername/multimodel/issues)

## ğŸ”— ç›¸å…³èµ„æº

- [PyTorch å®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/)
- [Transformers åº“](https://huggingface.co/transformers/)
- [OpenCV æ–‡æ¡£](https://docs.opencv.org/)
- [Librosa æ–‡æ¡£](https://librosa.org/)

## ğŸ“‹ æ›´æ–°æ—¥å¿—

### v0.1.0 (2024-12-19)
- âœ¨ åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- ğŸ¯ æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å¤„ç†
- ğŸ”€ å®ç°å¤šç§æ¨¡æ€èåˆæ–¹æ³•
- ğŸ› ï¸ æä¾›å‘½ä»¤è¡Œå·¥å…·
- ğŸ“– å®Œæ•´çš„æ–‡æ¡£å’Œç¤ºä¾‹

---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼**
